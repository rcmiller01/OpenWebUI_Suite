name: root

services:
  # Core Pipeline Services
  gateway:
    build: { context: ./00-pipelines-gateway }
    restart: unless-stopped
    env_file: [ .env, .env.openrouter ]
    networks: [ owui ]
    depends_on:
      policy: { condition: service_started }
      intent: { condition: service_started }
      memory: { condition: service_started }
      feeling: { condition: service_started }
      telemetry: { condition: service_started }
    ports: [ "8000:8000" ]
    extra_hosts: [ "host.docker.internal:host-gateway" ]
    volumes:
      - gateway_data:/data
    environment:
      - GATEWAY_DB=/data/gateway.db
      - ENABLE_PROJECTS=true
      # OpenRouter Refactor Configuration
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY:-}
      - OPENROUTER_GATEWAY_URL=http://gateway:8000
      - OPENROUTER_GATEWAY_TIMEOUT=${OPENROUTER_GATEWAY_TIMEOUT:-60}
      # Local Fallback Configuration
      - LLAMACPP_HOST=${LLAMACPP_HOST:-localhost}
      - LLAMACPP_PORT=${LLAMACPP_PORT:-8080}
      - LLAMACPP_TIMEOUT=${LLAMACPP_TIMEOUT:-30}
      # Tool Integration
      - N8N_WEBHOOK_URL=${N8N_WEBHOOK_URL:-http://192.168.50.145:5678/webhook/openrouter-router}
      - MCP_ENDPOINT=${MCP_ENDPOINT:-http://core3:8765}
      # Memory Service
      - MEMORY_SERVICE_URL=http://memory:8002
      # Service URLs
      - FEELING_URL=http://feeling:8103
      - INTENT_URL=http://intent:8101
      # OpenRouter Models (New Refactor)
      - MODEL_TOOLCALL=deepseek/deepseek-chat
      - MODEL_VISION=zhipuai/glm-4v-9b
      - MODEL_EXPLICIT=venice/uncensored:free
      - MODEL_CODER=qwen/qwen-2.5-coder-32b-instruct
      # Routing Configuration
      - ENABLE_CONTENT_ANALYSIS=${ENABLE_CONTENT_ANALYSIS:-true}
      - ENABLE_LOCAL_FALLBACK=${ENABLE_LOCAL_FALLBACK:-true}
      - AUTO_MODEL_SELECTION=${AUTO_MODEL_SELECTION:-true}
    healthcheck:
      test: ["CMD-SHELL","curl -fsS http://localhost:8000/health || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3

  intent:
    build: { context: ./01-intent-router }
    restart: unless-stopped
    env_file: [ .env ]
    environment:
      - ALLOW_EXTERNAL_FOR_REGULATED=${ALLOW_EXTERNAL_FOR_REGULATED:-0}
      - OPENROUTER_PRIORITIES_TECH=${OPENROUTER_PRIORITIES_TECH:-openai/gpt-4o,anthropic/claude-3-5-sonnet-20241022,google/gemini-pro-1.5,meta-llama/llama-3.1-70b-instruct,qwen/qwen-2.5-72b-instruct}
      - OPENROUTER_PRIORITIES_LEGAL=${OPENROUTER_PRIORITIES_LEGAL:-anthropic/claude-3-5-sonnet-20241022,openai/gpt-4o,cohere/command-r-plus,meta-llama/llama-3.1-70b-instruct}
      - OPENROUTER_PRIORITIES_PSYCHOTHERAPY=${OPENROUTER_PRIORITIES_PSYCHOTHERAPY:-anthropic/claude-3-5-sonnet-20241022,openai/gpt-4o,meta-llama/llama-3.1-70b-instruct}
      - OPENROUTER_PRIORITIES_REGULATED=${OPENROUTER_PRIORITIES_REGULATED:-meta-llama/llama-3.1-8b-instruct,microsoft/phi-3-mini-128k-instruct,qwen/qwen-2.5-7b-instruct}
    networks: [ owui ]
    expose: [ "8101" ]
    ports: [ "8101:8101" ]
    depends_on:
      policy: { condition: service_started }
      memory: { condition: service_started }
    healthcheck:
      test: ["CMD-SHELL","curl -fsS http://localhost:8101/healthz || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3

  memory:
    build: { context: ./02-memory-2.0 }
    restart: unless-stopped
    env_file: [ .env ]
    networks: [ owui ]
    expose: [ "8102" ]
    ports: [ "8102:8102" ]
    volumes:
      - memory_data:/data
    healthcheck:
      test: ["CMD-SHELL","curl -fsS http://localhost:8102/healthz || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3

  feeling:
    build: { context: ./03-feeling-engine }
    restart: unless-stopped
    env_file: [ .env ]
    networks: [ owui ]
    expose: [ "8103" ]
    ports: [ "8103:8103" ]
    healthcheck:
      test: ["CMD-SHELL","curl -fsS http://localhost:8103/healthz || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3

  merger:
    build: { context: ./04-hidden-multi-expert-merger }
    restart: unless-stopped
    env_file: [ .env ]
    networks: [ owui ]
    expose: [ "8104" ]
    ports: [ "8104:8104" ]
    healthcheck:
      test: ["CMD-SHELL","curl -fsS http://localhost:8104/healthz || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3

  drive:
    build: { context: ./05-drive-state }
    restart: unless-stopped
    env_file: [ .env ]
    networks: [ owui ]
    expose: [ "8105" ]
    ports: [ "8105:8105" ]
    healthcheck:
      test: ["CMD-SHELL","curl -fsS http://localhost:8105/healthz || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3

  byof:
    build: { context: ./06-byof-tool-hub }
    restart: unless-stopped
    env_file: [ .env ]
    networks: [ owui ]
    expose: [ "8106" ]
    ports: [ "8106:8106" ]
    healthcheck:
      test: ["CMD-SHELL","curl -fsS http://localhost:8106/healthz || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3

  tandoor:
    build: { context: ./07-tandoor-sidecar }
    restart: unless-stopped
    env_file: [ .env ]
    networks: [ owui ]
    expose: [ "8107" ]
    ports: [ "8107:8107" ]
    environment:
      - TANDOOR_URL=${TANDOOR_URL:-http://localhost:8080}
      - TANDOOR_API_TOKEN=${TANDOOR_API_TOKEN}
      - TANDOOR_USERNAME=${TANDOOR_USERNAME}
      - TANDOOR_PASSWORD=${TANDOOR_PASSWORD}
    healthcheck:
      test: ["CMD-SHELL","curl -fsS http://localhost:8107/healthz || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3

  openbb:
    build: { context: ./08-openbb-sidecar }
    restart: unless-stopped
    env_file: [ .env ]
    networks: [ owui ]
    expose: [ "8108" ]
    ports: [ "8108:8108" ]
    environment:
      - OPENBB_PAT=${OPENBB_PAT}
    healthcheck:
      test: ["CMD-SHELL","curl -fsS http://localhost:8108/healthz || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3

  daemon:
    build: { context: ./09-proactive-daemon }
    restart: unless-stopped
    env_file: [ .env ]
    networks: [ owui ]
    volumes:
      - daemon_data:/data
    environment:
      - GATEWAY_URL=http://gateway:8000
    healthcheck:
      test: ["CMD-SHELL","python -c 'import socket; s=socket.socket(); s.connect((\"localhost\", 8109)); s.close()' || exit 1"]
      interval: 60s
      timeout: 10s
      retries: 3

  multimodal:
    build: { context: ./10-multimodal-router }
    restart: unless-stopped
    env_file: [ .env ]
    networks: [ owui ]
    expose: [ "8110" ]
    ports: [ "8110:8110" ]
    extra_hosts: [ "host.docker.internal:host-gateway" ]
    environment:
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY}
      - STT_URL=http://stt-tts:8111/stt
    healthcheck:
      test: ["CMD-SHELL","curl -fsS http://localhost:8110/healthz || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3

  stt-tts:
    build: { context: ./11-stt-tts-gateway }
    restart: unless-stopped
    env_file: [ .env ]
    networks: [ owui ]
    expose: [ "8111" ]
    ports: [ "8111:8111" ]
    volumes:
      - stt_audio:/app/audio
    environment:
      - STT_MODEL_SIZE=${STT_MODEL_SIZE:-base}
      - TTS_MODEL_NAME=${TTS_MODEL_NAME:-tts_models/en/ljspeech/tacotron2-DDC_ph}
      - AUDIO_STORAGE_PATH=/app/audio
    healthcheck:
      test: ["CMD-SHELL","curl -fsS http://localhost:8111/healthz || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3

  avatar:
    build: { context: ./12-avatar-overlay }
    restart: unless-stopped
    env_file: [ .env ]
    networks: [ owui ]
    expose: [ "8112" ]
    ports: [ "8112:8112" ]
    healthcheck:
      test: ["CMD-SHELL","curl -fsS http://localhost:8112/ || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3

  policy:
    build: { context: ./13-policy-guardrails }
    restart: unless-stopped
    env_file: [ .env ]
    networks: [ owui ]
    expose: [ "8113" ]
    ports: [ "8113:8113" ]
    healthcheck:
      test: ["CMD-SHELL","curl -fsS http://localhost:8113/healthz || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3

  telemetry:
    build: { context: ./14-telemetry-cache }
    restart: unless-stopped
    env_file: [ .env ]
    networks: [ owui ]
    expose: [ "8114" ]
    ports: [ "8114:8114" ]
    volumes:
      - telemetry_data:/data
    environment:
      - REDIS_URL=${REDIS_URL:-redis://localhost:6379}
      - LOKI_URL=${LOKI_URL}
      - PROMETHEUS_URL=${PROMETHEUS_URL}
    healthcheck:
      test: ["CMD-SHELL","curl -fsS http://localhost:8114/healthz || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3

  fastvlm:
    build: { context: ./16-fastvlm-sidecar }
    restart: unless-stopped
    env_file: [ .env ]
    networks: [ owui ]
    expose: [ "8115" ]
    ports: [ "8115:8115" ]
    environment:
      - FASTVLM_MODEL=${FASTVLM_MODEL:-apple/fastvlm-2.7b}
      - DEVICE=${DEVICE:-cuda}
      - TORCH_DTYPE=${TORCH_DTYPE:-float16}
      - MAX_TOKENS=${MAX_TOKENS:-192}
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD-SHELL","curl -fsS http://localhost:8115/healthz || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3

  # --- UI (OpenWebUI Suite) ---
  openwebui-suite:
    build:
      context: ./openwebui-suite
      dockerfile: docker/Dockerfile
    restart: unless-stopped
    env_file: [ .env ]
    networks: [ owui ]
    depends_on:
      gateway: { condition: service_started }
    ports: [ "3000:3000" ]
    environment:
      - GATEWAY_URL=http://gateway:8000
      - ENABLE_PROJECTS=true
    healthcheck:
      test: ["CMD-SHELL","curl -fsS http://localhost:3000/ || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3

networks:
  owui:
    external: true
    name: ${OWUI_NETWORK:-root_owui}

volumes:
  gateway_data: {}
  memory_data: {}
  daemon_data: {}
  stt_audio: {}
  telemetry_data: {}
