# OpenWebUI Suite Environment Variables Example
# Copy this file to .env and customize values for your deployment

# === Core Configuration ===
HOST=0.0.0.0
PORT=8080
LOG_LEVEL=INFO
ENABLE_OTEL=true
OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4318
OTEL_SERVICE_NAME=pipelines-gateway
OTEL_RESOURCE_ATTRIBUTES=deployment.environment=dev
RATE_LIMIT_PER_MIN=120
PIPELINE_TIMEOUT_SECONDS=30
TASK_QUEUE_NAME=pipeline_tasks
TASK_DQL_NAME=pipeline_tasks_dlq
TASK_MAX_RETRIES=3
TASK_VISIBILITY_TIMEOUT=120
TASK_MAX_DEPTH=4

# === Ollama Configuration ===
OLLAMA_HOST=http://localhost:11434
OLLAMA_PORT=11434
OLLAMA_KEEP_ALIVE=5m
OLLAMA_NUM_PARALLEL=1
OLLAMA_ORIGINS=*
DEFAULT_LOCAL_MODEL=qwen2.5:3b-instruct-q4_K_M

# === OpenRouter Configuration ===
OPENROUTER_API_KEY=your-openrouter-api-key-here
OPENROUTER_MODEL=openai/gpt-4o-mini

# === Redis Configuration ===
REDIS_URL=redis://localhost:6379
REDIS_PASSWORD=your-redis-password-here

# === Database Configuration ===
DATABASE_URL=postgresql://user:password@localhost:5432/openwebui
POSTGRES_DB=openwebui
POSTGRES_USER=openwebui
POSTGRES_PASSWORD=your-postgres-password-here

# === Security Configuration ===
WEBUI_AUTH=true
WEBUI_SECRET_KEY=your-secret-key-here-change-in-production
WEBUI_NAME=OpenWebUI Suite
WEBUI_URL=http://localhost:3000
SUITE_SHARED_SECRET=your-hmac-secret-key-here

# === Plugin Configuration ===
OWUI_MEMORY_PATH=/data/memory.sqlite
OWUI_PLUGIN_TIMEOUT=30
OWUI_WIDGET_CACHE_TTL=3600

# === Service-Specific Configuration ===

# 00-pipelines-gateway
SERVICES_PATH=config/services.json

# 10-multimodal-router
VISION_MODEL=openai/gpt-4o-mini
AUDIO_MODEL=openai/gpt-4o-mini
MM_MAX_DOWNLOAD_BYTES=10485760

# 11-stt-tts-gateway
STT_MODEL_SIZE=base
TTS_MODEL_NAME=tts_models/en/ljspeech/tacotron2-DDC_ph
AUDIO_STORAGE_PATH=/tmp/owui_audio
MAX_AUDIO_SIZE_MB=50
STT_TTL_SECONDS=900
STT_MAX_UPLOAD_MB=25

# 13-policy-guardrails
POLICY_MAX_LENGTH=2000
POLICY_ENFORCE_SCHEMA=true

# 14-telemetry-cache
TELEMETRY_CACHE_VERSION=1.0.0
PROMETHEUS_PORT=9090

# 15-bytebot-gateway
BYTEBOT_URL=http://host.docker.internal:3000
BYTEBOT_API_KEY=your-bytebot-api-key

# 16-fastvlm-sidecar
FASTVLM_MODEL=openai/gpt-4o-mini

# === CORS Configuration ===
CORS_ORIGINS=http://localhost:3000,http://localhost:8080

# === Network Configuration ===
NETWORK_TIMEOUT=30
REQUEST_TIMEOUT=60

# === Logging Configuration ===
LOG_FORMAT=json
LOG_LEVEL=INFO

# === Development Configuration ===
DEBUG=false
TESTING=false
CI=false
